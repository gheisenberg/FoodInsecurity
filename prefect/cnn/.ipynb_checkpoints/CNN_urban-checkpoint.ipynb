{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Urban Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import random\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models\n",
    "#to dos:\n",
    "#generalize some code like pixel counts\n",
    "#create a preprocessing script and outsource methods\n",
    "#write different methods for normalization\n",
    "#write some quality control methods, e.g. pdf (probability density functions, outlyer detection - implement\n",
    "#into normalization methods)\n",
    "#more to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move Urban images to own directory\n",
    "\n",
    "def get_urban(urban_dir, orig_dir):\n",
    "\n",
    "    img_list = os.listdir(orig_dir)\n",
    "    survey_name = os.path.basename(orig_dir)\n",
    "    for img_name in img_list:\n",
    "        if img_name.endswith('.tif'):\n",
    "            img_dir = os.path.join(orig_dir, img_name)\n",
    "            img = rasterio.open(img_dir)\n",
    "            array = img.read()\n",
    "            if array.shape[1]< 500:\n",
    "                #Name tif data survey name + cluster\n",
    "                img_survey_name = img_name.replace(img_name[:6], survey_name)\n",
    "                urb_img = os.path.join(urban_dir, img_survey_name)\n",
    "                os.rename(img_dir, urb_img)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/home/shannon/Dokumente/Dokumente/studium/ASA/Projekt/NN/sentinel'\n",
    "def get_urban_img(base):\n",
    "    #Define folders\n",
    "    urban_dir = os.path.join(base, 'urban')\n",
    "    if not os.path.exists(urban_dir):\n",
    "        os.mkdir(urban_dir)\n",
    "\n",
    "    zip_files = os.listdir(base)\n",
    "    for zip_file in zip_files:\n",
    "        if zip_file.endswith('.zip'):\n",
    "            zip_dir = os.path.join(base, zip_file)\n",
    "            with ZipFile(zip_dir, 'r') as zipObj:\n",
    "                # Extract all the contents of zip file in current directory\n",
    "                zipObj.extractall(base)\n",
    "                img_dir_name = os.path.splitext(zip_file)[0]\n",
    "                img_dir = os.path.join(base, img_dir_name)\n",
    "                get_urban(urban_dir, img_dir)\n",
    "                shutil.rmtree(img_dir)\n",
    "\n",
    "    return urban_dir\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_source_file(water_file):\n",
    "   \n",
    "\n",
    "    water_source = water_file.drop(labels=['ID','cluster', 'residence','year'], axis = 1)\n",
    "    water_source = water_source.fillna(0)\n",
    "    water_source=  water_source.idxmax(axis=1)\n",
    "    water_source.name = 'source'\n",
    "\n",
    "\n",
    "    df = pd.concat([water_file['ID'], water_file['cluster'], water_source], axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_labels_df_for_img(csv_file, urban_dir, main_labels):\n",
    "\n",
    "    img_list = os.listdir(urban_dir)\n",
    "    water_file = pd.read_csv(csv_file)\n",
    "    label_list = []\n",
    "    column_names =  [\"name\", \"source\", \"label\"]\n",
    "    \n",
    "    water_file_max = get_main_source_file(water_file)\n",
    "    \n",
    "    for img in img_list:\n",
    "        for index, survey_name in enumerate(water_file_max['ID']): \n",
    "                survey_name = survey_name.replace('HR', 'GE', 1)\n",
    "                if survey_name in img:\n",
    "                    #find for this row in dataframe labels corresponding cluster and check with this if it is filename of image\n",
    "                    cluster = water_file_max.loc[index]['cluster']\n",
    "                    #cluster solely not enough as e.g. 1 may also be in 100, 101, 110, ....\n",
    "                    cluster_string = '000'+str(int(cluster))+'.tif'\n",
    "                    if cluster_string in img:\n",
    "                        source = water_file_max.loc[index]['source']\n",
    "                        if source in main_labels:\n",
    "                            img_label = [img, source, source]\n",
    "                            label_list.append(img_label)\n",
    "                        else:\n",
    "                            img_dir = os.path.join(urban_dir,img)\n",
    "                            os.remove(img_dir)\n",
    "                            \n",
    "    #Get data frame for label list                        \n",
    "    label_array = np.array(label_list)\n",
    "    label_df = pd.DataFrame(label_array, columns = column_names) \n",
    "\n",
    "    label_df.label = pd.Categorical(pd.factorize(label_df.label)[0] + 1)\n",
    "\n",
    "    print(label_df)\n",
    "    \n",
    "    return label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def created_data_sets(urban_dir):\n",
    "\n",
    "    # Divide into training (80%), validation (10%), test(10%) data sets\n",
    "    img_list = os.listdir(urban_dir)\n",
    "\n",
    "    #Create  validation, training und test folder\n",
    "\n",
    "    train_dir = os.path.join(urban_dir,'training')\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "\n",
    "    val_dir = os.path.join(urban_dir,'validation')\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.mkdir(val_dir)\n",
    "\n",
    "    test_dir = os.path.join(urban_dir,'test')\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.mkdir(test_dir)\n",
    "\n",
    "    #Split into the data sets and move them to their respective folder\n",
    "    X_train, X_rem = train_test_split(img_list, train_size=0.8)\n",
    "\n",
    "    X_val, X_test = train_test_split(X_rem, train_size = 0.5)\n",
    "\n",
    "    for img in X_train:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            train_img = os.path.join(train_dir, img)\n",
    "            os.rename(img_dir, train_img)\n",
    "\n",
    "    for img in X_val:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            val_img = os.path.join(val_dir, img)\n",
    "            os.rename(img_dir, val_img)\n",
    "\n",
    "    for img in X_test:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            test_img = os.path.join(test_dir, img)\n",
    "            os.rename(img_dir, test_img)\n",
    "    \n",
    "    \n",
    "    return train_dir, val_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative calculation way of mean and std if dataset is not too big\n",
    "def calc_mean_std(data_dir):\n",
    "    \n",
    "    img_list = os.listdir(data_dir)\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    #to do: pls generalize code - read out the amount of pixel!\n",
    "    pixels = np.ndarray(shape=(len(img_list), 13,201, 201))\n",
    "\n",
    "    #Create \"array of all images\"\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        img = rasterio.open(img_dir)\n",
    "        array = img.read()\n",
    "        array = array.astype('float32')\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0, a_max = 10000)\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "        pixels[i] = array\n",
    "        \n",
    "    #Calculate Mean and Standard deviation along images (axis 0), width & heigth(axis:2,3) for each channel (axis:1)       \n",
    "    means = pixels.mean(axis=(0,2,3), dtype='float64')\n",
    "    stds = pixels.std(axis=(0,2,3), dtype='float64')\n",
    "\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean for each channel over all pixels for training set; for validation and test set you need to take\n",
    "#mean and std of training set as well as in real case scenarios you don't know them beforehand to calculate them\n",
    "def calc_mean(data_dir):\n",
    "    \n",
    "    img_list = os.listdir(data_dir)\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    #pixels = np.ndarray(shape=(len(img_list), 13,201, 201))\n",
    "    #Variable to save the summation of the pixels values\n",
    "    sum_arr = 0\n",
    "    #Count of pixels\n",
    "    #to do: pls generalize code - read out the amount of pixel!\n",
    "    sum_pixel = 201*201*len(img_list)\n",
    "\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        with rasterio.open(img_dir) as img:\n",
    "            array = img.read()\n",
    "        array = array.astype('float32')\n",
    "        array[np.isnan(array)] = 0\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0,a_max = 10000)\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "        #pixels[i] = array\n",
    "        sum_arr += array.sum(axis = (1,2))\n",
    "        \n",
    "    #Calculate mean\n",
    "    means = sum_arr/sum_pixel\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate standard deviation (note:mean function has to be executed beforehand as it is required as input)\n",
    "def calc_std(means, data_dir):\n",
    "    img_list = os.listdir(data_dir)\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    \n",
    "    sum_arr = 0\n",
    "    #Count of pixels\n",
    "    #to do: pls generalize code - read out the amount of pixel!\n",
    "    sum_pixel = 201*201*len(img_list)\n",
    "    \n",
    "    #Work out mean and take it ^2\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        with rasterio.open(img_dir) as img:\n",
    "            array = img.read()\n",
    "        array = array.astype('float32')\n",
    "        array[np.isnan(array)] = 0\n",
    "\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0,a_max = 10000)\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "    \n",
    "        array = np.power(array.transpose(1,2,0) - means, 2).transpose(2, 0, 1)\n",
    "        sum_arr += array.sum(axis = (1,2))\n",
    "    \n",
    "    stds = np.sqrt(sum_arr/sum_pixel)\n",
    "    \n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip to 10.000\n",
    "#201x201 size\n",
    "#shuffle randomly order\n",
    "#normalize \n",
    "def generator(x_dir, labels, batch_size, means, stds):\n",
    "\n",
    "    x_list = os.listdir(x_dir)\n",
    "    assert all([i.endswith('.tif') for i in x_list])\n",
    "    #Shuffle elements in list, so that batches consists of images of different surveys\n",
    "    random.shuffle(x_list)\n",
    "\n",
    "    batch_x = np.zeros(shape=(batch_size, 13,201, 201))\n",
    "    batch_y = np.zeros(shape=(batch_size,3), dtype=int)\n",
    "    batch_ele = 0\n",
    "\n",
    "    for x in x_list:\n",
    "        #Get training sample x\n",
    "        img_dir = os.path.join(x_dir, x)\n",
    "        with rasterio.open(img_dir) as img:\n",
    "            array = img.read().astype(\"float32\")\n",
    "        \n",
    "        array[np.isnan(array)] = 0\n",
    "        assert not np.any(np.isnan(array)), \"Float\"\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0,a_max = 10000)\n",
    "\n",
    "        assert not np.any(np.isnan(array)), \"Crop to 10000\"\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "        \n",
    "        #Normalize the array\n",
    "        array = ((array.transpose(1,2,0)-means)/stds).transpose(2, 0, 1)\n",
    "        assert not np.any(np.isnan(array)), \"Normalize\"\n",
    "        # Add to batch\n",
    "        batch_x[batch_ele] = array     \n",
    "\n",
    "        #Get corresponding Label y\n",
    "        #find corresponding surveynames (row-value in filename of image)\n",
    "        '''for index, survey_name in enumerate(labels['ID']): \n",
    "            survey_name = survey_name.replace('HR', 'GE', 1)\n",
    "            if survey_name in x:\n",
    "                #find for this row in dataframe labels corresponding cluster and check with this if it is filename of image\n",
    "                cluster = labels.loc[index]['cluster']\n",
    "                #cluster solely not enough as e.g. 1 may also be in 100, 101, 110, ....\n",
    "                cluster_string = '000'+str(cluster)+'.tif'\n",
    "                if cluster_string in x:\n",
    "                    one_hot = np.zeros(shape = 3)\n",
    "                    label_pos = (labels.loc[index]['label'])-1\n",
    "                    print(labels.loc[index]['label'], label_pos)\n",
    "                    #One hot encoding\n",
    "                    one_hot[label_pos] = 1\n",
    "                    batch_y[batch_ele] = one_hot'''\n",
    "        \n",
    "        for index, survey_name in enumerate(labels['name']):\n",
    "            if survey_name in x:\n",
    "                one_hot = np.zeros(shape = 3)\n",
    "                label_pos = (labels.loc[index]['label'])-1\n",
    "                #One hot encoding\n",
    "                one_hot[label_pos] = 1\n",
    "                batch_y[batch_ele] = one_hot\n",
    "                \n",
    "        #Check if batch is already full (Note: Index in batch array is from 0...4 hence we need to add +1 to batch_ele)\n",
    "        if (batch_ele+1) == batch_size:\n",
    "            batch_x = batch_x.transpose(0,2,3,1)\n",
    "            yield batch_x,batch_y\n",
    "            #Reset settings -> Start of next batch creation\n",
    "            batch_ele = 0\n",
    "            batch_x = np.zeros(shape=(batch_size, 13,201, 201))\n",
    "            batch_y = np.zeros(shape=(batch_size, 3), dtype=int)\n",
    "\n",
    "        else:\n",
    "            batch_ele += 1\n",
    "    \n",
    "    \n",
    "#    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved urbane images to seperate folder\n",
      "                     name       source label\n",
      "0    AOGE71FL00000124.tif        piped     1\n",
      "1    AOGE71FL00000121.tif  groundwater     2\n",
      "2    AOGE71FL00000101.tif        piped     1\n",
      "3    AOGE71FL00000100.tif        piped     1\n",
      "4    AOGE71FL00000094.tif        piped     1\n",
      "..                    ...          ...   ...\n",
      "356  BFGE71FL00000164.tif        piped     1\n",
      "357  BFGE71FL00000163.tif        piped     1\n",
      "358  BFGE71FL00000162.tif        piped     1\n",
      "359  BFGE71FL00000149.tif  groundwater     2\n",
      "360  BFGE71FL00000144.tif        piped     1\n",
      "\n",
      "[361 rows x 3 columns]\n",
      "Add to label names categorical labels\n",
      "Split up data set into training, validation and test data\n",
      "Calculated mean and standard deviation for each channel (for training set)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#PARAMETERS\n",
    "base = '/home/shannon/Dokumente/Dokumente/studium/ASA/Projekt/NN/sentinel/'\n",
    "orig_dir = os.path.join(base, 'AOGE71FL')\n",
    "water_source_file = \"/home/shannon/Dokumente/Dokumente/studium/ASA/Projekt/SatelliteImage__GEE/correlation/SAV_Data/water-source/joined-surveys-2013-grouped.csv\"\n",
    "batch_size = 5\n",
    "# 3 Main label categories (which are kept)\n",
    "main_labels = ['piped', 'groundwater', 'bottled water']\n",
    "    \n",
    "\n",
    "#Functions\n",
    "urban_dir =  get_urban_img(base)# has to change if all surveys are used!\n",
    "print('Moved urbane images to seperate folder')\n",
    "\n",
    "labels_df = get_labels_df_for_img(water_source_file, urban_dir, main_labels)\n",
    "#labels_df = get_labels(water_source_file, urban_dir)\n",
    "print('Add to label names categorical labels')\n",
    "\n",
    "train_dir, val_dir, test_dir = created_data_sets(urban_dir)\n",
    "print('Split up data set into training, validation and test data')\n",
    "\n",
    "means = calc_mean(train_dir)\n",
    "stds = calc_std(means, train_dir)\n",
    "print('Calculated mean and standard deviation for each channel (for training set)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created x and y for training data\n"
     ]
    }
   ],
   "source": [
    "training_generator = generator(train_dir, labels_df, batch_size, means, stds)\n",
    "#Check if shape is correct\n",
    "print('Created x and y for training data')\n",
    "'''for data_batch, labels_batch in training_generator:\n",
    "    print('This is the shape of the training data batch:', data_batch.shape)\n",
    "    print('This is the shape of the training label batch:', labels_batch.shape)\n",
    "    break'''\n",
    "\n",
    "validation_generator = generator(val_dir, labels_df, batch_size, means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 14:25:04.906470: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(201, 201, 13)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 199, 199, 16)      1888      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 97, 97, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,340,803\n",
      "Trainable params: 3,340,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 14:25:05.693018: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-22 14:25:05.705508: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2096155000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 270ms/step - loss: 1.3546 - accuracy: 0.5078\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 298ms/step - loss: 0.5161 - accuracy: 0.7889\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 448ms/step - loss: 0.5733 - accuracy: 0.6878\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 436ms/step - loss: 0.6973 - accuracy: 0.6544\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 445ms/step - loss: 0.4408 - accuracy: 0.8278\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 477ms/step - loss: 0.6135 - accuracy: 0.6939\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 357ms/step - loss: 0.5100 - accuracy: 0.5639\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 358ms/step - loss: 0.5768 - accuracy: 0.7983\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 368ms/step - loss: 0.6009 - accuracy: 0.6772\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 339ms/step - loss: 0.6190 - accuracy: 0.4044\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "            training_generator,\n",
    "            steps_per_epoch=5,\n",
    "            epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESNET Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
