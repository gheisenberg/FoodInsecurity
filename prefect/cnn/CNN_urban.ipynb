{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Urban Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import random\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "#to dos:\n",
    "#generalize some code like pixel counts\n",
    "#create a preprocessing script and outsource methods\n",
    "#write different methods for normalization\n",
    "#write some quality control methods, e.g. pdf (probability density functions, outlyer detection - implement\n",
    "#into normalization methods)\n",
    "#more to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CPUs Available:  1\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 09:57:33.472079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 09:57:33.473297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 09:57:33.474457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 09:57:33.480231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-09-13 09:57:33.480240: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices(\"CPU\")))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move Urban images to own directory urban\n",
    "def get_urban(urban_dir:str, orig_dir: str, channels: int):\n",
    "    \n",
    "    #List all images\n",
    "    img_list = os.listdir(orig_dir)\n",
    "    survey_name = os.path.basename(orig_dir)\n",
    "    \n",
    "    channel_size = len(channels)\n",
    "    \n",
    "    for img_name in img_list:\n",
    "        if img_name.endswith('.tif'):\n",
    "            img_dir = os.path.join(orig_dir, img_name)\n",
    "            with rasterio.open(img_dir) as img:\n",
    "                if len(channels) == 0:\n",
    "                    try:\n",
    "                        array = img.read()\n",
    "                        channel_size = array.shape[0]\n",
    "                    except Exception as e:\n",
    "                        print(e, 'img_dir is', img_dir)\n",
    "                        continue\n",
    "                else:\n",
    "                    try:\n",
    "                        array = img.read(channels)\n",
    "                        channel_size = array.shape[0]\n",
    "                    except Exception as e:\n",
    "                        print(e, 'img_dir is', img_dir)\n",
    "                        continue\n",
    "            if array.shape[1]< 500:\n",
    "                #Name tif data survey name + cluster\n",
    "                #img_survey_name = img_name.replace(img_name[:6], survey_name)\n",
    "                urb_img = os.path.join(urban_dir, img_name)\n",
    "                os.rename(img_dir, urb_img)\n",
    "                \n",
    "    \n",
    "    return channel_size\n",
    "\n",
    "#Extract from each zip-file (each survey) all images which belongs to urban category (less than 500x500 pixels) and\n",
    "#move them to own directory\n",
    "def get_urban_img(img_zip_dir: str,base: str, channels: int):\n",
    "    \n",
    "    channel_size = 0\n",
    "    \n",
    "    #Create Urban Folder if not existing\n",
    "    urban_dir = os.path.join(base, 'urban')\n",
    "    if not os.path.exists(urban_dir):\n",
    "        os.mkdir(urban_dir)\n",
    "\n",
    "        \n",
    "    zip_files = os.listdir(img_zip_dir)\n",
    "    #Extract for each survey zip file all files into a temporary directory\n",
    "    for zip_file in zip_files:\n",
    "        \n",
    "        if zip_file.endswith('.zip'):\n",
    "            #Current zip file directory\n",
    "            zip_dir = os.path.join(img_zip_dir, zip_file)\n",
    "            #Unzip all files to img_dir (temporary directory)\n",
    "            with ZipFile(zip_dir, 'r') as zipObj:\n",
    "                \n",
    "                img_dir_name = os.path.splitext(zip_file)[0]\n",
    "                img_dir = os.path.join(base, img_dir_name)\n",
    "                # Extract all the contents of zip file into temporary directory \n",
    "                zipObj.extractall(img_dir)\n",
    "                # Jump into get_urban to move all urban images to the urban folder; return channel size\n",
    "                channels_num = get_urban(urban_dir, img_dir, channels)\n",
    "                #If channel size is not zero replace channel size with new value\n",
    "                if channels_num != 0:\n",
    "                    channel_size = channels_num\n",
    "                #Delete temporary directory\n",
    "                shutil.rmtree(img_dir)\n",
    "\n",
    "    return urban_dir, channel_size\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe where the column source refers to the water source which was named the most\n",
    "\n",
    "#Get the index of the last position of surveyname\n",
    "def get_pos_last_letter(cluster_name:str):\n",
    "    \n",
    "    #Reverse string\n",
    "    string = cluster_name[::-1]\n",
    "    #Check for first non-digit entry\n",
    "    for i in string:\n",
    "        if i.isalpha():\n",
    "            #Get position in reversed string\n",
    "            pos_reversed = string.find(i)\n",
    "            # 'Translate' Position of reversed string for non-reversed string\n",
    "            pos = len(cluster_name)-pos_reversed-1\n",
    "            break\n",
    "            \n",
    "    return pos\n",
    "\n",
    "def get_cluster_num_from_img_name(img:str):\n",
    "    \n",
    "    cluster_num = None\n",
    "    #Remove .tif (BFGE71FL0000203.tif )\n",
    "    img = img[:img.rfind('.')]\n",
    "    \n",
    "    #Remove survey name (alphabetich letter, BFGE71FL0000203)\n",
    "    #Check where survey name ends by finding last alphabetic letter\n",
    "    pos_last_alpha = get_pos_last_letter(img)\n",
    "    #Get cluster (including zeros) (0000203)\n",
    "    cluster_0 = img[pos_last_alpha+1:]\n",
    "    \n",
    "    #Get cluster number by finding first entry in remaining string which is not 0 as they typically have the form\n",
    "    #0000203 (want 203)\n",
    "    num_start = None\n",
    "    for str_index in range(0, len(cluster_0)):\n",
    "        if cluster_0[str_index] != '0':\n",
    "            num_start = str_index\n",
    "            break\n",
    "    if num_start is None:\n",
    "        cluster_num = 0\n",
    "    else:\n",
    "        cluster_num = cluster_0[num_start:]\n",
    "            \n",
    "    return cluster_num\n",
    "    \n",
    "    \n",
    "def get_main_source_file(water_file:pd.DataFrame):\n",
    "   \n",
    "    #Remove unnamed column\n",
    "    water_file = water_file.loc[:, ~water_file.columns.str.contains('^Unnamed')]\n",
    "    #Remove all unnecessary columns for our purpose\n",
    "    water_source = water_file.drop(labels=['ID','cluster', 'residence','year'], axis = 1)\n",
    "    #replace Na with 0 for the next step idxmax\n",
    "    water_source = water_source.fillna(0)\n",
    "    #Get a \"df\" where for each cluster the most dominating water source is given\n",
    "    water_source=  water_source.idxmax(axis=1)\n",
    "    #Naming of the column with most dominating water source\n",
    "    water_source.name = 'source'\n",
    "\n",
    "    #Merge, columns with ID and cluster of original df with the 'df' (which has the dominating water source)\n",
    "    df = pd.concat([water_file['ID'], water_file['cluster'], water_source], axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Create label dataframe where next to name (image name (Survey name+Cluster number)) the label in string format\n",
    "#and categorial format (number) is provided, but only for sentinel images which main source belongs to the main label\n",
    "#defined prior (which we want to classify); if they don't belong to one of those main labels thoses images are removed\n",
    "def get_labels_df_for_img(csv_file:str, urban_dir:str, main_labels:list, corr_GE_HR_file:str):\n",
    "    \n",
    "    #List all images in urban directory\n",
    "    img_list = os.listdir(urban_dir)\n",
    "    #Read in the Water file CSV file \n",
    "    water_file = pd.read_csv(csv_file)\n",
    "    #Create empty list for the labels (used as temporary storage before transforming it int a dataframe)\n",
    "    label_list = []\n",
    "    #Define column_names for the final data frame \n",
    "    column_names =  [\"name\", \"source\", \"label\"]\n",
    "    #Jump into function to get water source data frame where a column for the most dominating source (value is a\n",
    "    #string indicating the most dominating source for each cluster replaces the columns of possible water source and\n",
    "    #the count how often they were named by a cluster)\n",
    "    water_file_max = get_main_source_file(water_file)\n",
    "    #Read in file which connects Geodata files with HR data files\n",
    "    corr_ge_hr = pd.read_csv(corr_GE_HR_file)\n",
    "\n",
    "    #Iterate over all images\n",
    "    for img in img_list:\n",
    "        #no_label -> for kicking out image who dont have a label\n",
    "        no_label = True\n",
    "        #Iterate over all rows of the water_file_max data frame\n",
    "        for index, survey_name in enumerate(water_file_max['ID']): \n",
    "                #Get corresponding GeoData file name for HR file survey name via the df corr_ge_hr\n",
    "                idx = corr_ge_hr.index[corr_ge_hr['HR'] == survey_name]\n",
    "                ge_name = corr_ge_hr.iloc[idx[0]]['GE']\n",
    "                #Check if GeoData file name is in the image name (only survey name, not cluster checked yet)\n",
    "                if ge_name in img:\n",
    "                    #Get cluster number from image; note +.tif to ensure that e.g. 1 is not true for e.g. AOGe....2104.tif\n",
    "                    cluster_img = int(get_cluster_num_from_img_name(img))\n",
    "                    #Get cluster number from possible fitting water source df row\n",
    "                    cluster_df = int(water_file_max.loc[index]['cluster'])\n",
    "                    #check if the cluster numbers are identical\n",
    "                    if cluster_img == cluster_df:\n",
    "                        no_label = False\n",
    "                        #Check if label is part of the main labels (if not remove the image)\n",
    "                        #Get water source\n",
    "                        source = water_file_max.loc[index]['source']\n",
    "                        #Check if source in main labels (predefined parameter)\n",
    "                        #If yes, add current image name, and the water source twice (one will be turned to a numerical category)\n",
    "                        if source in main_labels:\n",
    "                            img_label = [img, source, source]\n",
    "                            label_list.append(img_label)\n",
    "                            print('Kept', img, survey_name, cluster_df, source)\n",
    "                            break\n",
    "                        else:\n",
    "                            #If not,delete image from the directory urban\n",
    "                            img_dir = os.path.join(urban_dir,img)\n",
    "                            os.remove(img_dir)\n",
    "                            print('Deleted',img, survey_name, cluster_df, source)\n",
    "                            break\n",
    "        if no_label == True:\n",
    "            #If no corresponding label was found delete from urban_dir\n",
    "            img_dir = os.path.join(urban_dir,img)\n",
    "            os.remove(img_dir)\n",
    "            print('Removed as no label',img)\n",
    "                            \n",
    "                            \n",
    "    #Get data frame for label list                        \n",
    "    label_array = np.array(label_list)\n",
    "    label_df = pd.DataFrame(label_array, columns = column_names) \n",
    "    #Turn label column (second water source) from string entries to categorical entries\n",
    "    label_df.label = pd.Categorical(pd.factorize(label_df.label)[0])\n",
    "\n",
    "    return label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data set into training, validation, and testing; each subset gets its own folder\n",
    "\n",
    "#Get ratio between validation to test set to be able to split the remaining data set properly (prior: Split into\n",
    "#training set and remaining set)\n",
    "def ratio_val_to_test(val:float, test:float):\n",
    "    \n",
    "    total = val + test\n",
    "    one_perc = 100.00/total\n",
    "    val_ratio = one_perc * val*0.01\n",
    "    \n",
    "    return val_ratio\n",
    "\n",
    "def created_data_sets(urban_dir:str, split_size):\n",
    "\n",
    "    print('split size', type(split_size))\n",
    "    img_list = os.listdir(urban_dir)\n",
    "\n",
    "    #Create  validation, training und test folder\n",
    "\n",
    "    train_dir = os.path.join(urban_dir,'training')\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "\n",
    "    val_dir = os.path.join(urban_dir,'validation')\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.mkdir(val_dir)\n",
    "\n",
    "    test_dir = os.path.join(urban_dir,'test')\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.mkdir(test_dir)\n",
    "\n",
    "    #Split into the data sets and move them to their respective folder\n",
    "    \n",
    "    X_train, X_rem = train_test_split(img_list, train_size= split_size[0])\n",
    "    \n",
    "    X_val, X_test = train_test_split(X_rem, train_size = ratio_val_to_test(split_size[1], split_size[2]))\n",
    "\n",
    "    for img in X_train:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            train_img = os.path.join(train_dir, img)\n",
    "            os.rename(img_dir, train_img)\n",
    "\n",
    "    for img in X_val:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            val_img = os.path.join(val_dir, img)\n",
    "            os.rename(img_dir, val_img)\n",
    "\n",
    "    for img in X_test:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            test_img = os.path.join(test_dir, img)\n",
    "            os.rename(img_dir, test_img)\n",
    "    \n",
    "    \n",
    "    return train_dir, val_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative calculation way of mean and std if dataset is not too big\n",
    "def calc_mean_std(data_dir:str, input_height, input_width,clipping_values, channels, channel_size):\n",
    "    \n",
    "    img_list = os.listdir(data_dir)\n",
    "    \n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    \n",
    "    pixels = np.ndarray(shape(len(img_list), channel_size, input_height, input_width))\n",
    "    \n",
    "    #Create \"array of all images\"\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        with rasterio.open(img_dir) as img:\n",
    "            if len(channels) == 0:\n",
    "                array = img.read()\n",
    "            else:\n",
    "                array = img.read(channels)\n",
    "\n",
    "            \n",
    "        array = array.astype('float32')\n",
    "        #Clipping\n",
    "        array = np.clip(array,a_min = clipping_values[0], a_max = clipping_values[1])\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:input_height,:input_width]\n",
    "        pixels[i] = array\n",
    "        \n",
    "    #Calculate Mean and Standard deviation along images (axis 0), width & heigth(axis:2,3) for each channel (axis:1)       \n",
    "    means = pixels.mean(axis=(0,2,3), dtype='float64')\n",
    "    stds = pixels.std(axis=(0,2,3), dtype='float64')\n",
    "\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean for each channel over all pixels for training set; for validation and test set you need to take\n",
    "#mean and std of training set as well as in real case scenarios you don't know them beforehand to calculate them\n",
    "def calc_mean(data_dir:str,input_height, input_width, clipping_values, channels):\n",
    "    \n",
    "    img_list = os.listdir(data_dir)\n",
    "    \n",
    "    #Ensures that only tif data are in the current directory, if not it will throw an error\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    \n",
    "    #Variable to save the summation of the pixels values\n",
    "    sum_arr = 0\n",
    "    #Count of pixels\n",
    "    sum_pixel = input_height*input_width*len(img_list)\n",
    "\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        with rasterio.open(img_dir) as img:\n",
    "            #Read in image with all channels\n",
    "            if len(channels) == 0:\n",
    "                array = img.read()\n",
    "            #Only read defined channels of the image\n",
    "            else:\n",
    "                array = img.read(channels)\n",
    "        \n",
    "        array = array.astype('float32')\n",
    "        #Replace NaN with zeros (for calculation required)\n",
    "        array[np.isnan(array)] = 0\n",
    "        #Clipping\n",
    "        array = np.clip(array,a_min = clipping_values[0],a_max = clipping_values[1])\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:input_height,:input_width]\n",
    "        #Adding the sum over the input and height for each channel seperately up\n",
    "        sum_arr += array.sum(axis = (1,2))\n",
    "        \n",
    "    #Calculate mean for each channel\n",
    "    means = sum_arr/sum_pixel\n",
    "    \n",
    "    #return channelwise mean (#mean == # channels)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate standard deviation (note:mean function has to be executed beforehand as it is required as input)\n",
    "def calc_std(means, data_dir, input_height, input_width, clipping_values, channels):\n",
    "    \n",
    "    img_list = os.listdir(data_dir)\n",
    "    #Ensure all data are tif data in current directory\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    \n",
    "    sum_arr = 0\n",
    "    #Count of pixels\n",
    "    sum_pixel = input_height*input_width*len(img_list)\n",
    "    \n",
    "    # Sum each array/image up (channelwise) with each other, after substracting mean(s) from each array and take it ^2\n",
    "    #each one seperately -> Check standard deviatin equation\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        \n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        with rasterio.open(img_dir) as img:\n",
    "            if len(channels) == 0:\n",
    "                #Read in all channels\n",
    "                array = img.read()\n",
    "            else:\n",
    "                #Only read in predefined channels\n",
    "                array = img.read(channels)\n",
    "\n",
    "        array = array.astype('float32')\n",
    "        array[np.isnan(array)] = 0\n",
    "\n",
    "        #Clipping\n",
    "        array = np.clip(array,a_min = clipping_values[0],a_max =clipping_values[1])\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:input_height,:input_width]\n",
    "    \n",
    "        array = np.power(array.transpose(1,2,0) - means, 2).transpose(2, 0, 1)\n",
    "        sum_arr += array.sum(axis = (1,2))\n",
    "    \n",
    "    #Second part of equation\n",
    "    stds = np.sqrt(sum_arr/sum_pixel)\n",
    "    \n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create class weights for the prediction model as our data set is imbalanced (acoount higher weight to classes with \n",
    "#less samples)\n",
    "def create_class_weights_dict(train_dir:str, labels_df:str):\n",
    "    \n",
    "    train_sample  = os.listdir(train_dir)\n",
    "    label_array = np.zeros(len(train_sample), dtype=int)\n",
    "    index = 0\n",
    "\n",
    "    #Create array with the labels used (training labels) such that we get a list of the form [1 1 1 0 2 1 2....]\n",
    "    for sample in train_sample:\n",
    "        got = False\n",
    "        for pos, survey_name in enumerate(labels_df['name']):\n",
    "            if survey_name in sample:\n",
    "                label = labels_df.loc[pos]['label']\n",
    "                label_array[index] = label\n",
    "                index += 1\n",
    "                got = True\n",
    "        if got == False:\n",
    "            print(sample)\n",
    "     \n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(label_array), label_array)\n",
    "    class_weights_dict = dict(enumerate(class_weights,))\n",
    "    \n",
    "    return class_weights_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate iterable object for model.fit()\n",
    "def generator(x_dir, labels, batch_size, means, stds, input_height, input_width, clipping_values, channels, channel_size, num_labels):\n",
    "\n",
    "    x_list = os.listdir(x_dir)\n",
    "    assert all([i.endswith('.tif') for i in x_list])\n",
    "    #Shuffle elements in list, so that batches consists of images of different surveys\n",
    "    random.shuffle(x_list)\n",
    "    #generate batches (x : input, y: label)\n",
    "    batch_x = np.zeros(shape=(batch_size, channel_size,input_height, input_width))\n",
    "    batch_y = np.zeros(shape=(batch_size,num_labels), dtype=int)\n",
    "    #Iterator\n",
    "    batch_ele = 0\n",
    "\n",
    "    for x in x_list:\n",
    "        #Get training sample x\n",
    "        img_dir = os.path.join(x_dir, x)\n",
    "        \n",
    "        with rasterio.open(img_dir) as img:\n",
    "            #if we want to use all channels\n",
    "            if len(channels) == 0:\n",
    "                array = img.read().astype(\"float32\")\n",
    "            else:\n",
    "                array = img.read(channels).astype(\"float32\")\n",
    "\n",
    "        \n",
    "        array[np.isnan(array)] = 0\n",
    "        assert not np.any(np.isnan(array)), \"Float\"\n",
    "        #Clipping\n",
    "        array = np.clip(array,a_min = clipping_values[0],a_max = clipping_values[1])\n",
    "\n",
    "        assert not np.any(np.isnan(array)), \"After clipping\"\n",
    "        #Ensure that that all arrays have the same size via cropping\n",
    "        array = array[:,:input_height,:input_width]\n",
    "        \n",
    "        #Normalize the array\n",
    "        array = ((array.transpose(1,2,0)-means)/stds).transpose(2, 0, 1)\n",
    "        assert not np.any(np.isnan(array)), \"Normalize\"\n",
    "        # Add to batch\n",
    "        batch_x[batch_ele] = array     \n",
    "        \n",
    "        #Get corresponding label y\n",
    "        for index, survey_name in enumerate(labels['name']):\n",
    "            if survey_name in x:\n",
    "                one_hot = np.zeros(shape = num_labels)\n",
    "                label_pos = (labels.loc[index]['label'])\n",
    "                #One hot encoding\n",
    "                one_hot[label_pos] = 1\n",
    "                batch_y[batch_ele] = one_hot\n",
    "                \n",
    "        #Check if batch is already full (Note: Index in batch array is from 0...4 hence we need to add +1 to batch_ele)\n",
    "        if (batch_ele+1) == batch_size:\n",
    "            batch_x = batch_x.transpose(0,2,3,1)\n",
    "            #Return of batch_x,batch_y\n",
    "            yield batch_x.astype(np.float32), batch_y.astype(np.float32)\n",
    "            #Reset settings -> Start of next batch generation\n",
    "            batch_ele = 0\n",
    "            batch_x = np.zeros(shape=(batch_size, channel_size,input_height, input_width))\n",
    "            batch_y = np.zeros(shape=(batch_size, num_labels), dtype=int)\n",
    "\n",
    "        else:\n",
    "            batch_ele += 1\n",
    "    \n",
    "    \n",
    "#    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "\n",
    "#base where Script and CSV File about water sources are stored\n",
    "base = '/mnt/datadisk/shannon/NN/'\n",
    "img_dir = '/mnt/datadisk/sciebo/prefect_prj/data/Sentinel_images'\n",
    "\n",
    "water_source_file = os.path.join(base,\"joined-surveys-2013-grouped.csv\")\n",
    "corr_GE_HR_file = os.path.join(base, \"corresponding_ge_hr_survey.csv\")\n",
    "batch_size = 20\n",
    "# 3 Main label categories (which are kept)\n",
    "main_labels = ['piped', 'groundwater', 'bottled water']\n",
    "num_labels = len(main_labels)\n",
    "#Training, validation and test set size \n",
    "#[Training size, validation size, test size]\n",
    "split_size = [0.8,0.1,0.1]\n",
    "#Input height\n",
    "input_height  = 200\n",
    "#Input width \n",
    "input_width = 200\n",
    "#Minimum and maximum values (for clipping above and below those values)\n",
    "#[Minimum value, maximum value]\n",
    "clipping_values = [0, 3000]\n",
    "\n",
    "#channels (define channels which should be used, if all should list can stay empty channel = [])\n",
    "channels = [4,3,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess part\n",
    "\n",
    "Run the following part only once at the beginning if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function : To create your urban directory with all image belonging to the urban type in it\n",
    "urban_dir, channel_size =  get_urban_img(img_dir, base, channels)\n",
    "print('Moved urbane images to seperate folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create Label Data Frame (Saved after splitting them up)\n",
    "urban_dir ='/mnt/datadisk/shannon/NN/urban'\n",
    "labels_df = get_labels_df_for_img(water_source_file, urban_dir, main_labels, corr_GE_HR_file)\n",
    "print(\"Add to label names categorical labels and removed images which don't belong to one of the main labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training, validation and test sets\n",
    "train_dir, val_dir, test_dir = created_data_sets(urban_dir, split_size)\n",
    "print('Split up data set into training, validation and test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After splitting them to ensure that labels_df.to_csv is not part of one of the three subsets\n",
    "labels_df.to_csv('/mnt/datadisk/shannon/NN/urban/labels_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Part : Model\n",
    "\n",
    "Means and Std Calculation part may take a while (but not as long as the once before); hence, you may save means and std as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defined again if part before is skipped\n",
    "train_dir = '/mnt/datadisk/shannon/NN/urban/training'\n",
    "val_dir = '/mnt/datadisk/shannon/NN/urban/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean and standard deviation, print them such that you could save them to variables if wanted (do not have to \n",
    "#to calculate mean & standard deviation again)\n",
    "means = calc_mean(train_dir, input_height, input_width, clipping_values, channels)\n",
    "stds = calc_std(means, train_dir, input_height, input_width, clipping_values, channels)\n",
    "print(means, stds)\n",
    "print('Calculated mean and standard deviation for each channel (for training set)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in labels_df(if you closed the program in between)\n",
    "labels_df = pd.read_csv('/mnt/datadisk/shannon/NN/urban/labels_df.csv')\n",
    "channel_size = 3\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create class weights\n",
    "class_weights = create_class_weights_dict(train_dir, labels_df)\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This partonly checks if the normalization worked fine\n",
    "training_generator = generator(train_dir, labels_df, batch_size, means, stds, input_height, input_width, clipping_values, channels, channel_size, num_labels)\n",
    "#Check if shape is correct\n",
    "print('Created x and y for training data')\n",
    "for data_batch, labels_batch in training_generator:\n",
    "    print('This is the shape of the training data batch:', data_batch.shape)\n",
    "    print('This is the shape of the training label batch:', labels_batch.shape)\n",
    "    samples = data_batch\n",
    "    break\n",
    "\n",
    "validation_generator = generator(val_dir, labels_df, batch_size, means, stds, input_height, input_width, clipping_values, channels, channel_size, num_labels)\n",
    "\n",
    "print('The minimum value is', np.min(samples))\n",
    "print('The maximum value is', np.max(samples))\n",
    "print('The mean is', np.mean(samples))\n",
    "print('The standard deviation is', np.std(samples))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(samples.flatten(), bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronal Network part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part generates the actually training generator for the NN\n",
    "from functools import partial\n",
    "\n",
    "train_generator_func = partial(generator, train_dir, labels_df, batch_size, means, stds, input_height, input_width, clipping_values, channels, channel_size, num_labels)\n",
    "train_ds = tf.data.Dataset.from_generator(train_generator_func, \n",
    "                                          output_types=(tf.float32, tf.float32), \n",
    "                                          output_shapes=((batch_size, 200, 200, 3), (batch_size, 3)),\n",
    "                                         )\n",
    "\n",
    "'''for elem in train_ds.take(2):\n",
    "    print(elem)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part generates the actually validation generator for the NN\n",
    "val_generator_func = partial(generator, val_dir, labels_df, batch_size, means, stds, input_height, input_width, clipping_values, channels, channel_size, num_labels)\n",
    "val_ds = tf.data.Dataset.from_generator(val_generator_func, \n",
    "                                          output_types=(tf.float32, tf.float32), \n",
    "                                          output_shapes=((batch_size, 200, 200, 3), (batch_size, 3)),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESNET\n",
    "\n",
    "base_model = tensorflow.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights = None,\n",
    "    input_shape = (200, 200, channel_size),\n",
    "    pooling = None,\n",
    "    classes = 3,\n",
    "    \n",
    ")\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "base_model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = base_model.fit(\n",
    "            train_ds,\n",
    "            class_weight=class_weights,\n",
    "            validation_data=val_ds,\n",
    "            epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
