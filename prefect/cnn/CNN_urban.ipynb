{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1ff7e9",
   "metadata": {},
   "source": [
    "# CNN for Urban Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527b84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import random\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d0583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03820494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move Urban images to own directory\n",
    "\n",
    "def get_urban(base, orig_dir):\n",
    "\n",
    "    #Define folders\n",
    "    urban_dir = os.path.join(base, 'urban')\n",
    "    if not os.path.exists(urban_dir):\n",
    "        os.mkdir(urban_dir)\n",
    "\n",
    "\n",
    "    img_list = os.listdir(orig_dir)\n",
    "    survey_name = os.path.basename(orig_dir)\n",
    "    for img_name in img_list:\n",
    "        if img_name.endswith('.tif'):\n",
    "            img_dir = os.path.join(orig_dir, img_name)\n",
    "            img = rasterio.open(img_dir)\n",
    "            array = img.read()\n",
    "            if array.shape[1]< 500:\n",
    "                #Name tif data survey name + cluster\n",
    "                img_survey_name = img_name.replace(img_name[:6], survey_name)\n",
    "                urb_img = os.path.join(urban_dir, img_survey_name)\n",
    "                os.rename(img_dir, urb_img)\n",
    "                \n",
    "    return urban_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6899e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9450511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_source_file(water_file):\n",
    "   \n",
    "\n",
    "    water_source = water_file.drop(labels=['ID','cluster', 'residence','year'], axis = 1)\n",
    "    water_source = water_source.fillna(0)\n",
    "    water_source=  water_source.idxmax(axis=1)\n",
    "    water_source.name = 'source'\n",
    "\n",
    "\n",
    "    df = pd.concat([water_file['ID'], water_file['cluster'], water_source], axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_labels_df_for_img(csv_file, urban_dir, main_labels):\n",
    "\n",
    "    img_list = os.listdir(urban_dir)\n",
    "    water_file = pd.read_csv(csv_file)\n",
    "    label_list = []\n",
    "    column_names =  [\"name\", \"source\", \"label\"]\n",
    "    \n",
    "    water_file_max = get_main_source_file(water_file)\n",
    "    \n",
    "    for img in img_list:\n",
    "        for index, survey_name in enumerate(water_file_max['ID']): \n",
    "                survey_name = survey_name.replace('HR', 'GE', 1)\n",
    "                if survey_name in img:\n",
    "                    #find for this row in dataframe labels corresponding cluster and check with this if it is filename of image\n",
    "                    cluster = water_file_max.loc[index]['cluster']\n",
    "                    #cluster solely not enough as e.g. 1 may also be in 100, 101, 110, ....\n",
    "                    cluster_string = '000'+str(int(cluster))+'.tif'\n",
    "                    if cluster_string in img:\n",
    "                        source = water_file_max.loc[index]['source']\n",
    "                        if source in main_labels:\n",
    "                            img_label = [img, source, source]\n",
    "                            label_list.append(img_label)\n",
    "                        else:\n",
    "                            img_dir = os.path.join(urban_dir,img)\n",
    "                            os.remove(img_dir)\n",
    "                            \n",
    "    #Get data frame for label list                        \n",
    "    label_array = np.array(label_list)\n",
    "    label_df = pd.DataFrame(label_array, columns = column_names) \n",
    "\n",
    "    label_df.label = pd.Categorical(pd.factorize(label_df.label)[0] + 1)\n",
    "\n",
    "    print(label_df)\n",
    "    \n",
    "    return label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac447854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def created_data_sets(urban_dir):\n",
    "\n",
    "    # Divide into training (80%), validation (10%), test(10%) data sets\n",
    "    img_list = os.listdir(urban_dir)\n",
    "\n",
    "    #Create  validation, training und test folder\n",
    "\n",
    "    train_dir = os.path.join(urban_dir,'training')\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "\n",
    "    val_dir = os.path.join(urban_dir,'validation')\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.mkdir(val_dir)\n",
    "\n",
    "    test_dir = os.path.join(urban_dir,'test')\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.mkdir(test_dir)\n",
    "\n",
    "    #Split into the data sets and move them to their respective folder\n",
    "    X_train, X_rem = train_test_split(img_list, train_size=0.8)\n",
    "\n",
    "    X_val, X_test = train_test_split(X_rem, train_size = 0.5)\n",
    "\n",
    "    for img in X_train:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            train_img = os.path.join(train_dir, img)\n",
    "            os.rename(img_dir, train_img)\n",
    "\n",
    "    for img in X_val:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            val_img = os.path.join(val_dir, img)\n",
    "            os.rename(img_dir, val_img)\n",
    "\n",
    "    for img in X_test:\n",
    "            img_dir = os.path.join(urban_dir, img)\n",
    "            test_img = os.path.join(test_dir, img)\n",
    "            os.rename(img_dir, test_img)\n",
    "    \n",
    "    \n",
    "    return train_dir, val_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08a55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative calculation way of mean and std if dataset is not too big\n",
    "def calc_mean_std(data_dir):\n",
    "    \n",
    "    img_list = os.listdir(data_dir)\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    pixels = np.ndarray(shape=(len(img_list), 3,201, 201))\n",
    "\n",
    "    #Create \"array of all images\"\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        img = rasterio.open(img_dir)\n",
    "        array = img.read()\n",
    "        array = array.astype('float32')\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0, a_max = 10000)\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "        pixels[i] = array\n",
    "        \n",
    "    #Calculate Mean and Standard deviation along images (axis 0), width & heigth(axis:2,3) for each channel (axis:1)       \n",
    "    means = pixels.mean(axis=(0,2,3), dtype='float64')\n",
    "    stds = pixels.std(axis=(0,2,3), dtype='float64')\n",
    "\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e0200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean for each channel over all pixels for training set; for validation and test set you need to take\n",
    "#mean and std of training set as well as in real case scenarios you don't know them beforehand to calculate them\n",
    "def calc_mean(data_dir):\n",
    "    \n",
    "    img_list = os.listdir(data_dir)\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    #pixels = np.ndarray(shape=(len(img_list), 3,201, 201))\n",
    "    #Variable to save the summation of the pixels values\n",
    "    sum_arr = 0\n",
    "    #Count of pixels\n",
    "    sum_pixel = 201*201*len(img_list)\n",
    "\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        img = rasterio.open(img_dir)\n",
    "        array = img.read()\n",
    "        array = array.astype('float32')\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0,a_max = 10000)\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "        #pixels[i] = array\n",
    "        sum_arr += array.sum(axis = (1,2))\n",
    "        \n",
    "    #Calculate mean\n",
    "    means = sum_arr/sum_pixel\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b85db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate standard deviation (note:mean function has to be executed beforehand as it is required as input)\n",
    "def calc_std(means, data_dir):\n",
    "    img_list = os.listdir(data_dir)\n",
    "    assert all([i.endswith('.tif') for i in img_list])\n",
    "    \n",
    "    sum_arr = 0\n",
    "    #Count of pixels\n",
    "    sum_pixel = 201*201*len(img_list)\n",
    "    \n",
    "    #Work out mean and take it ^2\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        img_dir = os.path.join(data_dir, img_name)\n",
    "        img = rasterio.open(img_dir)\n",
    "        array = img.read()\n",
    "        array = array.astype('float32')\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0,a_max = 10000)\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "    \n",
    "        array = np.power(array.transpose(1,2,0) - means, 2).transpose(2, 0, 1)\n",
    "        sum_arr += array.sum(axis = (1,2))\n",
    "    \n",
    "    stds = np.sqrt(sum_arr/sum_pixel)\n",
    "    \n",
    "    return stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639a27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip to 10.000\n",
    "#201x201 size\n",
    "#shuffle randomly order\n",
    "#normalize \n",
    "def generator(x_dir, labels, batch_size, means, stds):\n",
    "\n",
    "    x_list = os.listdir(x_dir)\n",
    "    assert all([i.endswith('.tif') for i in x_list])\n",
    "    #Shuffle elements in list, so that batches consists of images of different surveys\n",
    "    random.shuffle(x_list)\n",
    "\n",
    "    batch_x = np.zeros(shape=(batch_size, 3,201, 201))\n",
    "    batch_y = np.zeros(shape=(batch_size,3), dtype=int)\n",
    "    batch_ele = 0\n",
    "\n",
    "    for x in x_list:\n",
    "        #Get training sample x\n",
    "        img_dir = os.path.join(x_dir, x)\n",
    "        img = rasterio.open(img_dir)\n",
    "        array = img.read()\n",
    "        array = array.astype('float32')\n",
    "        #Clip to max 10.000\n",
    "        array = np.clip(array,a_min = 0,a_max = 10000)\n",
    "        #Ensure that that all arrays have the same size\n",
    "        array = array[:,:201,:201]\n",
    "        #Normalize the array\n",
    "        array = ((array.transpose(1,2,0)-means)/stds).transpose(2, 0, 1)\n",
    "        # Add to batch\n",
    "        batch_x[batch_ele] = array     \n",
    "\n",
    "        #Get corresponding Label y\n",
    "        #find corresponding surveynames (row-value in filename of image)\n",
    "        '''for index, survey_name in enumerate(labels['ID']): \n",
    "            survey_name = survey_name.replace('HR', 'GE', 1)\n",
    "            if survey_name in x:\n",
    "                #find for this row in dataframe labels corresponding cluster and check with this if it is filename of image\n",
    "                cluster = labels.loc[index]['cluster']\n",
    "                #cluster solely not enough as e.g. 1 may also be in 100, 101, 110, ....\n",
    "                cluster_string = '000'+str(cluster)+'.tif'\n",
    "                if cluster_string in x:\n",
    "                    one_hot = np.zeros(shape = 3)\n",
    "                    label_pos = (labels.loc[index]['label'])-1\n",
    "                    print(labels.loc[index]['label'], label_pos)\n",
    "                    #One hot encoding\n",
    "                    one_hot[label_pos] = 1\n",
    "                    batch_y[batch_ele] = one_hot'''\n",
    "        \n",
    "        for index, survey_name in enumerate(labels['name']):\n",
    "            if survey_name in x:\n",
    "                one_hot = np.zeros(shape = 3)\n",
    "                label_pos = (labels.loc[index]['label'])-1\n",
    "                #One hot encoding\n",
    "                one_hot[label_pos] = 1\n",
    "                batch_y[batch_ele] = one_hot\n",
    "                \n",
    "        #Check if batch is already full (Note: Index in batch array is from 0...4 hence we need to add +1 to batch_ele)\n",
    "        if (batch_ele+1) == batch_size:\n",
    "            batch_x = batch_x.transpose(0,2,3,1)\n",
    "            yield batch_x,batch_y\n",
    "            #Reset settings -> Start of next batch creation\n",
    "            batch_ele = 0\n",
    "            batch_x = np.zeros(shape=(batch_size, 3,201, 201))\n",
    "            batch_y = np.zeros(shape=(batch_size, 3), dtype=int)\n",
    "\n",
    "        batch_ele += 1\n",
    "    \n",
    "    \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6985ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved urbane images to seperate folder\n",
      "                     name       source label\n",
      "0    AOGE71FL00000128.tif        piped     1\n",
      "1    AOGE71FL00000126.tif        piped     1\n",
      "2    AOGE71FL00000124.tif        piped     1\n",
      "3    AOGE71FL00000121.tif  groundwater     2\n",
      "4    AOGE71FL00000111.tif        piped     1\n",
      "..                    ...          ...   ...\n",
      "254  AOGE71FL00000529.tif        piped     1\n",
      "255  AOGE71FL00000528.tif        piped     1\n",
      "256  AOGE71FL00000527.tif        piped     1\n",
      "257  AOGE71FL00000523.tif  groundwater     2\n",
      "258  AOGE71FL00000520.tif        piped     1\n",
      "\n",
      "[259 rows x 3 columns]\n",
      "Add to label names categorical labels\n",
      "Split up data set into training, validation and test data\n",
      "Calculated mean and standard deviation for each channel (for training set)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#PARAMETERS\n",
    "base = '/home/shannon/Dokumente/Dokumente/studium/ASA/Projekt/NN/sentinel/'\n",
    "orig_dir = os.path.join(base, 'AOGE71FL')\n",
    "water_source_file = \"/home/shannon/Dokumente/Dokumente/studium/ASA/Projekt/SatelliteImage__GEE/correlation/SAV_Data/water-source/joined-surveys-2013-grouped.csv\"\n",
    "batch_size = 5\n",
    "# 3 Main label categories (which are kept)\n",
    "main_labels = ['piped', 'groundwater', 'bottled water']\n",
    "    \n",
    "\n",
    "#Functions\n",
    "urban_dir = get_urban(base, orig_dir) # has to change if all surveys are used!\n",
    "print('Moved urbane images to seperate folder')\n",
    "\n",
    "labels_df = get_labels_df_for_img(water_source_file, urban_dir, main_labels)\n",
    "#labels_df = get_labels(water_source_file, urban_dir)\n",
    "print('Add to label names categorical labels')\n",
    "\n",
    "train_dir, val_dir, test_dir = created_data_sets(urban_dir)\n",
    "print('Split up data set into training, validation and test data')\n",
    "\n",
    "means = calc_mean(train_dir)\n",
    "stds = calc_std(means, train_dir)\n",
    "print('Calculated mean and standard deviation for each channel (for training set)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43441768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created x and y for training data\n",
      "This is the shape of the training data batch: (5, 201, 201, 3)\n",
      "This is the shape of the training label batch: (5, 3)\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "training_generator = generator(train_dir, labels_df, batch_size, means, stds)\n",
    "#Check if shape is correct\n",
    "print('Created x and y for training data')\n",
    "for data_batch, labels_batch in training_generator:\n",
    "    print('This is the shape of the training data batch:', data_batch.shape)\n",
    "    print('This is the shape of the training label batch:', labels_batch.shape)\n",
    "    print(type(labels_batch[1][1]))\n",
    "    break\n",
    "\n",
    "validation_generator = generator(val_dir, labels_df, batch_size, means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c365c0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 13:51:17.582950: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(201, 201, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cafe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 199, 199, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 97, 97, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               17334784  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 17,359,907\n",
      "Trainable params: 17,359,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1bfeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 13:51:17.923083: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-20 13:51:17.934614: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2095900000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - loss: 2.3266 - accuracy: 0.6307WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 2.5115 - accuracy: 0.6456 - val_loss: 2.3637 - val_accuracy: 0.5667\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 2.3314 - accuracy: 0.3889\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.5404 - accuracy: 0.8361\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.6487 - accuracy: 0.7006\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 0.4610 - accuracy: 0.7372\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.4549 - accuracy: 0.7322\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.4791 - accuracy: 0.6444\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.3684 - accuracy: 0.7872\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.3370 - accuracy: 0.7483\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.4715 - accuracy: 0.6606\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "            training_generator,\n",
    "            steps_per_epoch=5,\n",
    "            epochs=10,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07ba36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c68132d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
