{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "from zipfile import ZipFile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if ZIP Data with FL.zip ending was downloaded\n",
    "def remove_FL(dir_name):\n",
    "    #Remove all Zip-Data which doesn't include .sav\n",
    "    folder = os.listdir(dir_name)\n",
    "    for item in folder:\n",
    "        if item.endswith(\"FL.zip\") or item.endswith(\"FL.ZIP\"):\n",
    "            os.remove(os.path.join(dir_name, item))\n",
    "            \n",
    "# Optional if not only Houehold Surveys (HR) were downloaded\n",
    "def remove_all_except_HR(dir_name):\n",
    "    folder = os.listdir(dir_name)\n",
    "    for item in folder:\n",
    "        if not \"HR\" in item[2:4] and (item.endswith(\".zip\") or item.endswith(\".ZIP\")):\n",
    "            os.remove(os.path.join(dir_name, item))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract solely the sav-file from the zip and save them into a seperate folder\n",
    "def get_sav(listOfFileNames, newpath, zipObject):\n",
    "\n",
    "    for fileName in listOfFileNames:\n",
    "        if fileName.endswith('.sav') or fileName.endswith('.SAV'):\n",
    "            # Extract a single file from zip\n",
    "            zipObject.extract(fileName, newpath)\n",
    "            \n",
    "            \n",
    "def extract_bigger_zip(zip_dir,filenames,newpath):\n",
    "    zips_dir = zip_dir[:zip_dir.find('.')]\n",
    "    if not os.path.exists(zips_dir):\n",
    "        os.makedirs(zips_dir)\n",
    "    with ZipFile(zip_dir, 'r') as zipObj:\n",
    "    #Extract all the contents of zip file in different directory\n",
    "        zipObj.extractall(zips_dir)\n",
    "\n",
    "    big_size = 0\n",
    "    big_zip = None\n",
    "    for item in filenames:\n",
    "        if item.endswith('.zip') or item.endswith('.ZIP'):\n",
    "            file_dir = os.path.join(zips_dir, item)\n",
    "            curr_size= os.stat(file_dir).st_size\n",
    "            if curr_size >= big_size:\n",
    "                big_size = curr_size\n",
    "                big_zip = file_dir\n",
    "    check_sav(big_zip,newpath)    \n",
    "    \n",
    "#Second mainpart for single zip file        \n",
    "def check_sav(zip_dir, newpath):\n",
    "    big_zip = None\n",
    "    with ZipFile(zip_dir, 'r') as zipObject:\n",
    "        listOfFileNames = zipObject.namelist()\n",
    "\n",
    "        if any((element.endswith('.sav') or element.endswith('.SAV')) for element in listOfFileNames):\n",
    "            get_sav(listOfFileNames, newpath, zipObject)\n",
    "        elif any((element.endswith('.zip') or element.endswith('.ZIP')) for element in listOfFileNames):\n",
    "            extract_bigger_zip(zip_dir, listOfFileNames, newpath)  \n",
    "            \n",
    "def delete_zip_folders(dir_name,newpath):\n",
    "    list_subfolders_with_paths = [f.path for f in os.scandir(dir_name) if f.is_dir()]\n",
    "    for folder in list_subfolders_with_paths:\n",
    "        if not folder == newpath:\n",
    "            shutil.rmtree(folder)\n",
    "#Main part-> runs through all zip files in directory  \n",
    "def extract_sav(dir_name, newpath):\n",
    "    #Create folder for SAV files\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    folder = os.listdir(dir_name)\n",
    "\n",
    "    for item in folder:\n",
    "        if item.endswith('.zip') or item.endswith('.ZIP'):\n",
    "            zip_dir = os.path.join(dir_name, item)\n",
    "            check_sav(zip_dir, newpath)\n",
    "            \n",
    "    delete_zip_folders(dir_name,newpath)\n",
    "    \n",
    "    return newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv data with information of year, water source, and region type for each cluster\n",
    "def get_csv(file, export_path):\n",
    "    df, meta = pyreadstat.read_sav(file, encoding = 'LATIN1')\n",
    "    meta_dict = dict(zip(meta.column_names, meta.column_labels))\n",
    "    cluster = None\n",
    "    water = None\n",
    "    year = None\n",
    "    residence = None\n",
    "    for i in meta_dict:\n",
    "        if meta_dict is None or meta_dict[i] is None:\n",
    "            print(meta_dict[i])\n",
    "        else:\n",
    "            if \"Source of drinking water\" in meta_dict[i]:\n",
    "                if not df[i].isnull().all().all():\n",
    "                    water = i\n",
    "            elif \"Cluster number\" in meta_dict[i] or \"cluster number\" in meta_dict[i]:\n",
    "                if not df[i].isnull().all().all():\n",
    "                    cluster = i\n",
    "            elif \"Year of interview\" in meta_dict[i] or \"year of interview\" in meta_dict[i]:\n",
    "                    if not df[i].isnull().all().all():\n",
    "                        year = i\n",
    "            elif \"Type of place of residence\" in meta_dict[i] or \"type of place of residence\" in meta_dict[i]:\n",
    "                    if not df[i].isnull().all().all():\n",
    "                        residence = i\n",
    "    # V113 Source of drinking water, V115 Time to get to water source\n",
    "    #V001 Cluster number\n",
    "    #year of interview\n",
    "    #Type of place of residence\n",
    "    \n",
    "    if cluster is not None and water is not None:\n",
    "        #print('Want to create CSV')\n",
    "        try:\n",
    "            crosstab = pd.crosstab(df[cluster], df[water].map(meta.variable_value_labels[water]),rownames = [\"Cluster\"],colnames = [\"Properties\"], dropna=True)\n",
    "            crosstab['Year'] = df[year]\n",
    "            crosstab['Residence'] = df[residence].map(meta.variable_value_labels[residence])\n",
    "            export = file[file.rfind('/'):file.rfind('.')]\n",
    "            #print(export)\n",
    "            crosstab.to_csv(export_path+export+'-water_source.csv')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(dir_sav, dir_csv):\n",
    "    if not os.path.exists(dir_csv):\n",
    "        os.makedirs(dir_csv)\n",
    "\n",
    "    directory = os.listdir(dir_sav)\n",
    "    for file in directory: \n",
    "        #print(\"This is the file\", file)\n",
    "        sav_path = os.path.join (dir_sav, file)\n",
    "        get_csv(sav_path, dir_csv)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_before_2013 (export_path):\n",
    "    before_2013 = os.path.join(export_path, \"before_2013\")\n",
    "    if not os.path.exists(before_2013):\n",
    "        os.makedirs(before_2013)\n",
    "\n",
    "    directory = os.listdir(export_path)    \n",
    "    for file in directory:\n",
    "        #print(file)\n",
    "        if file.endswith('.csv'):\n",
    "            csv_file = os.path.join(export_path, file)\n",
    "            survey_year = pd.read_csv(csv_file, usecols = ['Year'])\n",
    "            if survey_year['Year'].max()< 2013:\n",
    "                new_path = os.path.join(before_2013, file)\n",
    "                os.rename(csv_file, new_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_no_gps(dir_csv, dir_no_gps, dir_gps_zips):\n",
    "    if not os.path.exists(dir_no_gps):\n",
    "        os.makedirs(dir_no_gps)\n",
    "\n",
    "    water_dir = os.listdir(dir_csv)\n",
    "    gps_dir = os.listdir(dir_gps_zips)\n",
    "    \n",
    "    for water_file in water_dir:\n",
    "        if water_file.endswith('.csv'):\n",
    "            possible_gps_name = water_file.replace('HR', 'GE')[:water_file.rfind('-')]\n",
    "            if not any(possible_gps_name in gps_file for gps_file in gps_dir):\n",
    "                new_path = os.path.join(dir_no_gps, water_file)\n",
    "                old_path = os.path.join(dir_csv, water_file)\n",
    "                os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_csv(dir_csv):\n",
    "    directory = os.listdir(dir_csv)    \n",
    "    big_csv = pd.DataFrame()\n",
    "    # Path to joined file (if already existing delete to avoid adding it in the for-loop to the csv data)\n",
    "    path = os.path.join(dir_csv, 'joined-surveys-after-2003.csv')\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "    \n",
    "    for file in directory:\n",
    "        if file.endswith('.csv'):\n",
    "            csv_file = os.path.join(dir_csv, file)\n",
    "            current_csv = pd.read_csv(csv_file)\n",
    "            #Add ID as column to current_csv file; name clip at -water_source.csv\n",
    "            filename = os.path.basename(file)[:file.find('-')]\n",
    "            ID = [filename]*len(current_csv)\n",
    "            idx = 0\n",
    "            current_csv.insert(loc=idx, column='ID', value = ID)\n",
    "            #Append it to big csv file\n",
    "            big_csv = pd.concat([big_csv, current_csv])\n",
    "       \n",
    "    big_csv.to_csv(path,index = False)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_done\n",
      "remove_all_except_HR done\n",
      "created sav files\n",
      "None\n",
      "Create water source csv files\n",
      "Split into two subsets (before and after 2013)\n",
      "Moved all files without gps data into seperate subfolder\n"
     ]
    }
   ],
   "source": [
    "# Main part \n",
    "dir_corr = '/home/shannon/Dokumente/Dokumente/studium/ASA/Projekt/SatelliteImage__GEE/correlation/'\n",
    "dir_zip = os.path.join(dir_corr,'SAV_Data')\n",
    "dir_sav = os.path.join(dir_zip, 'SAV_file')\n",
    "dir_gps_zips = os.path.join(dir_corr, 'GPS_Data')\n",
    "dir_csv =  os.path.join(dir_zip, 'water-source')\n",
    "dir_no_gps = os.path.join(dir_csv, 'no_GPS_from_2013')\n",
    "\n",
    "remove_FL(dir_zip)\n",
    "print('FL_done')\n",
    "remove_all_except_HR(dir_zip)\n",
    "print('remove_all_except_HR done')\n",
    "extract_sav(dir_zip, dir_sav)\n",
    "print('created sav files')\n",
    "create_csv(dir_sav, dir_csv)\n",
    "print('Create water source csv files')\n",
    "split_before_2013(dir_csv)\n",
    "print('Split into two subsets (before and after 2013)')\n",
    "split_no_gps(dir_csv, dir_no_gps, dir_gps_zips)\n",
    "print('Moved all files without gps data into seperate subfolder')\n",
    "big_csv_path = create_single_csv(dir_csv) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please Note that the column names are rather diverse (1) although they may indicate the same source (e.g. *River/dam/lake/ponds/stream/canal/irrigation channel* and *Lake/pond/river/channel/irrigation channel*) or (2) there are different categories used (e.g. UGHR7IFL-water_source has the category *Bicycle with jerrycans* which others don't have)\n",
    "\n",
    "TZGE7AFL exisitiert als GPS datei aber nicht als HR TZHR7ASV; kein einzefall -> ungleich gewicht zwischen gps(mehr) und dhs (weniger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
