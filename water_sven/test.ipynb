{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 19:26:28.497404: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import VGG19\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 19:26:32.668829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.669076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.747165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.747372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.747553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.747726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.888412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.888617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.888785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.888938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.889088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.889331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.905250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.905442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.905621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.905789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.905963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.906105: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-06-10 19:26:32.906131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46747 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2024-06-10 19:26:32.908266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 19:26:32.908527: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-06-10 19:26:32.908563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46857 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 3s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 100, 100)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 100, 100)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 100, 100)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 50, 50)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 50, 50)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 256, 25, 25)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 256, 12, 12)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 512, 12, 12)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 512, 12, 12)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 512, 12, 12)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 512, 12, 12)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 512, 6, 6)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 512, 3, 3)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,075,009\n",
      "Trainable params: 21,075,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_model(model, neurons_l, type_m, out_classes, dropout=None):\n",
    "        #freeze layers of input model\n",
    "    #unfreeze at least one layer if unfreeze layers != 0\n",
    "    unfrozen_layers = max(1, round(len(model.layers) * 100/100))\n",
    "    freeze_layers = len(model.layers) - unfrozen_layers\n",
    "    for layer in model.layers[0:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    for neurons in neurons_l:\n",
    "        x = Dense(neurons, activation='relu')(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "    \n",
    "    if type_m == 'categorical':\n",
    "        out = Dense(out_classes, activation='softmax')(x)\n",
    "    elif type_m == 'regression':\n",
    "        out = Dense(1, kernel_initializer='normal')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=model.input, outputs=out)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(3, 100, 100))\n",
    "neurons_l = [1024, 512]\n",
    "type_m = 'regression'\n",
    "out_classes = 10  # This is only relevant if type_m is 'categorical'\n",
    "dropout = 0.5\n",
    "\n",
    "model = create_model(base_model, neurons_l, type_m, out_classes, dropout)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 19:26:36.248851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:26:36.607494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 100, 100)\n",
      "Test batch prediction shape: (10, 1)\n",
      "Test batch prediction shape: <class 'numpy.ndarray'>\n",
      "Test batch prediction: [[0.23973349]\n",
      " [0.23195314]\n",
      " [0.26145318]\n",
      " [0.26798415]\n",
      " [0.2451318 ]\n",
      " [0.25212687]\n",
      " [0.24894571]\n",
      " [0.25728992]\n",
      " [0.24228129]\n",
      " [0.24030724]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 19:26:37.480304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "test_input = np.random.rand(10, 3, 100, 100).astype(np.float32)\n",
    "pred = model.predict_on_batch(test_input)\n",
    "print(test_input.shape)\n",
    "print(\"Test batch prediction shape:\", pred.shape)\n",
    "print(\"Test batch prediction shape:\", type(pred))\n",
    "\n",
    "print(\"Test batch prediction:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable (<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32, numpy=\narray([[[[ 0.34119523,  0.09563112,  0.0177449 , ..., -0.11436455,\n          -0.05099866, -0.00299793],\n         [ 0.46418372,  0.03355668,  0.10245045, ..., -0.06945956,\n          -0.04020201,  0.04048637],\n         [ 0.39416704, -0.08419707, -0.03631314, ..., -0.10720515,\n          -0.03804016,  0.04690642]],\n\n        [[ 0.33999205,  0.13363543,  0.02129423, ..., -0.13025227,\n          -0.16508926, -0.06969624],\n         [ 0.41810837,  0.05260524,  0.09755926, ..., -0.09385028,\n          -0.20492788, -0.0573062 ],\n         [ 0.37740308, -0.07876257, -0.04775979, ..., -0.11827433,\n          -0.19008617, -0.01889699]],\n\n        [[-0.04484424,  0.06471398, -0.07631404, ..., -0.12629718,\n          -0.29905206, -0.2825364 ],\n         [-0.04806903, -0.00658076, -0.02234544, ..., -0.0878844 ,\n          -0.3915486 , -0.34632796],\n         [-0.04594866, -0.11583115, -0.14462094, ..., -0.12290562,\n          -0.35782176, -0.27979308]]],\n\n\n       [[[ 0.23215917,  0.133657  ,  0.12134422, ..., -0.1063385 ,\n           0.28406844,  0.3594997 ],\n         [ 0.30511212,  0.05677647,  0.21688674, ..., -0.06828708,\n           0.3440761 ,  0.44033417],\n         [ 0.2671299 , -0.07969447,  0.05988706, ..., -0.09225675,\n           0.31764674,  0.42209673]],\n\n        [[ 0.08978214,  0.18505956,  0.15264879, ..., -0.04266965,\n           0.25779948,  0.35873157],\n         [ 0.10385381,  0.08851637,  0.2392226 , ..., -0.01210995,\n           0.27064082,  0.40848857],\n         [ 0.09986369, -0.06240906,  0.07442063, ..., -0.02214639,\n           0.25912452,  0.423499  ]],\n\n        [[-0.30331427,  0.08002605, -0.03926321, ..., -0.12958746,\n          -0.19778992, -0.21510386],\n         [-0.37314063, -0.00698938,  0.02153259, ..., -0.09827439,\n          -0.2535741 , -0.25541356],\n         [-0.34100872, -0.13399366, -0.11510294, ..., -0.11911335,\n          -0.23109646, -0.19202407]]],\n\n\n       [[[-0.07260918,  0.10084777,  0.01313597, ..., -0.12594968,\n           0.1464741 ,  0.05009392],\n         [-0.07646758,  0.03879711,  0.09974211, ..., -0.08732687,\n           0.2247974 ,  0.10158388],\n         [-0.07573577, -0.07806503, -0.03540679, ..., -0.1208065 ,\n           0.20088433,  0.09790061]],\n\n        [[-0.246675  ,  0.1414054 ,  0.02605635, ..., -0.10128672,\n           0.16340195,  0.02832468],\n         [-0.3107071 ,  0.06031388,  0.10412455, ..., -0.06832542,\n           0.20279962,  0.05222717],\n         [-0.2803425 , -0.07094654, -0.0387974 , ..., -0.08843154,\n           0.18996507,  0.07766484]],\n\n        [[-0.33683276,  0.06601517, -0.08144748, ..., -0.13460518,\n          -0.1342358 , -0.27096185],\n         [-0.46453714, -0.00576723, -0.02660675, ..., -0.10017379,\n          -0.15603794, -0.32566148],\n         [-0.41602272, -0.11491341, -0.14672887, ..., -0.13079506,\n          -0.1379628 , -0.2658845 ]]]], dtype=float32)>) was not created in the distribution strategy scope of (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f82485184f0>). It is most likely because some layers, model, or optimizer was being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.\nwith strategy.scope():\n  model=_create_model()\n  model.compile(...)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m     49\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(base_model, neurons_l, type_m, out_classes, dropout)\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Print model summary\u001b[39;00m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:3609\u001b[0m, in \u001b[0;36mModel._validate_compile\u001b[0;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[1;32m   3607\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables:\n\u001b[1;32m   3608\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mvariable_created_in_scope(v):\n\u001b[0;32m-> 3609\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3610\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) was not created in the distribution \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3611\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrategy scope of (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). It is most likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3612\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause some layers, model, or optimizer was being \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3613\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated outside the distribution strategy scope. Try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3614\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto make sure your code looks similar \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3615\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the following.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mwith strategy.scope():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3616\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  model=_create_model()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3617\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  model.compile(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3618\u001b[0m             )\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;66;03m# Model metrics must be created in the same distribution strategy scope\u001b[39;00m\n\u001b[1;32m   3621\u001b[0m \u001b[38;5;66;03m# as the model.\u001b[39;00m\n\u001b[1;32m   3622\u001b[0m strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\n",
      "\u001b[0;31mValueError\u001b[0m: Variable (<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32, numpy=\narray([[[[ 0.34119523,  0.09563112,  0.0177449 , ..., -0.11436455,\n          -0.05099866, -0.00299793],\n         [ 0.46418372,  0.03355668,  0.10245045, ..., -0.06945956,\n          -0.04020201,  0.04048637],\n         [ 0.39416704, -0.08419707, -0.03631314, ..., -0.10720515,\n          -0.03804016,  0.04690642]],\n\n        [[ 0.33999205,  0.13363543,  0.02129423, ..., -0.13025227,\n          -0.16508926, -0.06969624],\n         [ 0.41810837,  0.05260524,  0.09755926, ..., -0.09385028,\n          -0.20492788, -0.0573062 ],\n         [ 0.37740308, -0.07876257, -0.04775979, ..., -0.11827433,\n          -0.19008617, -0.01889699]],\n\n        [[-0.04484424,  0.06471398, -0.07631404, ..., -0.12629718,\n          -0.29905206, -0.2825364 ],\n         [-0.04806903, -0.00658076, -0.02234544, ..., -0.0878844 ,\n          -0.3915486 , -0.34632796],\n         [-0.04594866, -0.11583115, -0.14462094, ..., -0.12290562,\n          -0.35782176, -0.27979308]]],\n\n\n       [[[ 0.23215917,  0.133657  ,  0.12134422, ..., -0.1063385 ,\n           0.28406844,  0.3594997 ],\n         [ 0.30511212,  0.05677647,  0.21688674, ..., -0.06828708,\n           0.3440761 ,  0.44033417],\n         [ 0.2671299 , -0.07969447,  0.05988706, ..., -0.09225675,\n           0.31764674,  0.42209673]],\n\n        [[ 0.08978214,  0.18505956,  0.15264879, ..., -0.04266965,\n           0.25779948,  0.35873157],\n         [ 0.10385381,  0.08851637,  0.2392226 , ..., -0.01210995,\n           0.27064082,  0.40848857],\n         [ 0.09986369, -0.06240906,  0.07442063, ..., -0.02214639,\n           0.25912452,  0.423499  ]],\n\n        [[-0.30331427,  0.08002605, -0.03926321, ..., -0.12958746,\n          -0.19778992, -0.21510386],\n         [-0.37314063, -0.00698938,  0.02153259, ..., -0.09827439,\n          -0.2535741 , -0.25541356],\n         [-0.34100872, -0.13399366, -0.11510294, ..., -0.11911335,\n          -0.23109646, -0.19202407]]],\n\n\n       [[[-0.07260918,  0.10084777,  0.01313597, ..., -0.12594968,\n           0.1464741 ,  0.05009392],\n         [-0.07646758,  0.03879711,  0.09974211, ..., -0.08732687,\n           0.2247974 ,  0.10158388],\n         [-0.07573577, -0.07806503, -0.03540679, ..., -0.1208065 ,\n           0.20088433,  0.09790061]],\n\n        [[-0.246675  ,  0.1414054 ,  0.02605635, ..., -0.10128672,\n           0.16340195,  0.02832468],\n         [-0.3107071 ,  0.06031388,  0.10412455, ..., -0.06832542,\n           0.20279962,  0.05222717],\n         [-0.2803425 , -0.07094654, -0.0387974 , ..., -0.08843154,\n           0.18996507,  0.07766484]],\n\n        [[-0.33683276,  0.06601517, -0.08144748, ..., -0.13460518,\n          -0.1342358 , -0.27096185],\n         [-0.46453714, -0.00576723, -0.02660675, ..., -0.10017379,\n          -0.15603794, -0.32566148],\n         [-0.41602272, -0.11491341, -0.14672887, ..., -0.13079506,\n          -0.1379628 , -0.2658845 ]]]], dtype=float32)>) was not created in the distribution strategy scope of (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f82485184f0>). It is most likely because some layers, model, or optimizer was being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.\nwith strategy.scope():\n  model=_create_model()\n  model.compile(...)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "def create_model(model, neurons_l, type_m, out_classes, dropout=None):\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    for neurons in neurons_l:\n",
    "        x = Dense(neurons, activation='relu')(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "    \n",
    "    if type_m == 'categorical':\n",
    "        out = Dense(out_classes, activation='softmax')(x)\n",
    "    elif type_m == 'regression':\n",
    "        out = Dense(1, kernel_initializer='normal')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=model.input, outputs=out)\n",
    "    return model\n",
    "\n",
    "# Create base model\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(3, 100, 100))\n",
    "\n",
    "# Define parameters\n",
    "neurons_l = [1024, 512]\n",
    "type_m = 'regression'\n",
    "out_classes = 10  # Only relevant if type_m is 'categorical'\n",
    "dropout = 0.5\n",
    "\n",
    "# Use MirroredStrategy for distributed training\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:\" + str(i) for i in [0,1]])\n",
    "\n",
    "with strategy.scope():\n",
    "    model = create_model(base_model, neurons_l, type_m, out_classes, dropout)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Test with a synthetic batch input\n",
    "test_input = np.random.rand(10, 3, 100, 100).astype(np.float32)\n",
    "# logger.debug(\"Test input data: %s\", test_input)\n",
    "\n",
    "pred = model.predict(test_input)\n",
    "# Print test output\n",
    "print(test_input.shape)\n",
    "print(\"Test batch prediction shape:\", pred.shape)\n",
    "print(\"Test batch prediction type:\", type(pred))\n",
    "print(\"Test batch prediction:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "DEBUG:__main__:Model created with layers:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 3, 100, 100)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 100, 100)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 100, 100)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 50, 50)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 50, 50)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 50, 50)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 128, 25, 25)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 256, 25, 25)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 256, 25, 25)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 256, 12, 12)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 512, 12, 12)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 512, 12, 12)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 512, 12, 12)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 512, 12, 12)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 512, 6, 6)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 512, 6, 6)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 512, 3, 3)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,075,009\n",
      "Trainable params: 21,075,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 19:29:24.060333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [50,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "DEBUG:__main__:Batch data shape: (10, 3, 100, 100)\n",
      "2024-06-10 19:29:24.084612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.084966: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:48\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2024-06-10 19:29:24.091245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.091408: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "DEBUG:__main__:Batch prediction shape: (10, 1)\n",
      "DEBUG:__main__:Batch data shape: (10, 3, 100, 100)\n",
      "2024-06-10 19:29:24.462171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.462519: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:64\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2024-06-10 19:29:24.465882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.466042: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "DEBUG:__main__:Batch prediction shape: (10, 1)\n",
      "DEBUG:__main__:Batch data shape: (10, 3, 100, 100)\n",
      "2024-06-10 19:29:24.553993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.554300: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:80\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2024-06-10 19:29:24.557471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.557621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "DEBUG:__main__:Batch prediction shape: (10, 1)\n",
      "DEBUG:__main__:Batch data shape: (10, 3, 100, 100)\n",
      "2024-06-10 19:29:24.639944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.640246: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:96\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2024-06-10 19:29:24.643438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.643589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "DEBUG:__main__:Batch prediction shape: (10, 1)\n",
      "DEBUG:__main__:Batch data shape: (10, 3, 100, 100)\n",
      "2024-06-10 19:29:24.730255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.730558: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:112\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "        dim {\n",
      "          size: 100\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2024-06-10 19:29:24.733815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-10 19:29:24.733964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [10,3,100,100]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "DEBUG:__main__:Batch prediction shape: (10, 1)\n",
      "DEBUG:__main__:Complete predictions shape: (50, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete predictions shape: (50, 1)\n",
      "Predictions: [[-0.01420981]\n",
      " [-0.04474981]\n",
      " [-0.00461541]\n",
      " [-0.03722925]\n",
      " [-0.00197983]\n",
      " [-0.01651862]\n",
      " [-0.00297237]\n",
      " [-0.01427188]\n",
      " [ 0.01288254]\n",
      " [-0.00117422]\n",
      " [-0.0077542 ]\n",
      " [-0.01310588]\n",
      " [-0.02000218]\n",
      " [-0.04665419]\n",
      " [-0.00359902]\n",
      " [-0.01954608]\n",
      " [-0.01405914]\n",
      " [-0.01254627]\n",
      " [-0.01834228]\n",
      " [ 0.00922775]\n",
      " [ 0.00778042]\n",
      " [-0.00880324]\n",
      " [ 0.00323083]\n",
      " [-0.02351457]\n",
      " [-0.01960595]\n",
      " [-0.03952255]\n",
      " [-0.01385491]\n",
      " [-0.02710311]\n",
      " [-0.00397971]\n",
      " [-0.03467187]\n",
      " [-0.03804477]\n",
      " [ 0.0037501 ]\n",
      " [-0.02806786]\n",
      " [-0.01269479]\n",
      " [-0.00957624]\n",
      " [-0.00251121]\n",
      " [-0.00830674]\n",
      " [-0.00585702]\n",
      " [-0.01625368]\n",
      " [-0.00856563]\n",
      " [-0.02051067]\n",
      " [-0.0295184 ]\n",
      " [ 0.00170929]\n",
      " [-0.02685451]\n",
      " [ 0.00751171]\n",
      " [-0.0301689 ]\n",
      " [-0.02217676]\n",
      " [-0.01135078]\n",
      " [-0.02497144]\n",
      " [-0.03294414]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "# Create the strategy\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:\" + str(i) for i in [0, 1]])\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def create_model(base_model, neurons_l, type_m, out_classes, dropout=None):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    for neurons in neurons_l:\n",
    "        x = Dense(neurons, activation='relu')(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "    \n",
    "    if type_m == 'categorical':\n",
    "        out = Dense(out_classes, activation='softmax')(x)\n",
    "    elif type_m == 'regression':\n",
    "        out = Dense(1, kernel_initializer='normal')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=base_model.input, outputs=out)\n",
    "    return model\n",
    "\n",
    "# Define parameters\n",
    "neurons_l = [1024, 512]\n",
    "type_m = 'regression'\n",
    "out_classes = 10  # Only relevant if type_m is 'categorical'\n",
    "dropout = 0.5\n",
    "\n",
    "with strategy.scope():\n",
    "    # Create base model\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(3, 100, 100))\n",
    "\n",
    "    # Create custom model within the strategy scope\n",
    "    model = create_model(base_model, neurons_l, type_m, out_classes, dropout)\n",
    "    \n",
    "    # Compile the model within the strategy scope\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Log model creation\n",
    "logger.debug('Model created with layers:')\n",
    "# for layer in model.layers:\n",
    "#     logger.debug(f\"Layer {layer.name}: {layer.get_weights()}\")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Create a multi-batch dataset\n",
    "batch_size = 10\n",
    "num_batches = 5\n",
    "data = np.random.rand(batch_size * num_batches, 3, 100, 100).astype(np.float32)\n",
    "labels = np.random.rand(batch_size * num_batches, 1).astype(np.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels)).batch(batch_size)\n",
    "\n",
    "# Predict on the dataset\n",
    "preds = []\n",
    "for batch_data, batch_labels in dataset:\n",
    "    logger.debug(f\"Batch data shape: {batch_data.shape}\")\n",
    "    pred = model.predict_on_batch(batch_data)\n",
    "    logger.debug(f\"Batch prediction shape: {pred.shape}\")\n",
    "    preds.append(pred)\n",
    "\n",
    "# Concatenate predictions to form the complete prediction array\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "# Print predictions\n",
    "logger.debug(f\"Complete predictions shape: {preds.shape}\")\n",
    "print(\"Complete predictions shape:\", preds.shape)\n",
    "print(\"Predictions:\", preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
